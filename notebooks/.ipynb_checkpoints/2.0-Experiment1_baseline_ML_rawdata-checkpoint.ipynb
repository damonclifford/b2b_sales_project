{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<script>\n",
    "  function code_toggle() {\n",
    "    if (code_shown){\n",
    "      $('div.input').hide('500');\n",
    "      $('#toggleButton').val('Show Code')\n",
    "    } else {\n",
    "      $('div.input').show('500');\n",
    "      $('#toggleButton').val('Hide Code')\n",
    "    }\n",
    "    code_shown = !code_shown\n",
    "  }\n",
    "\n",
    "  $( document ).ready(function(){\n",
    "    code_shown=false;\n",
    "    $('div.input').hide()\n",
    "  });\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" id=\"toggleButton\" value=\"Show Code\"></form>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<script>\n",
    "  $(document).ready(function(){\n",
    "    $('div.prompt').hide();\n",
    "    $('div.back-to-top').hide();\n",
    "    $('nav#menubar').hide();\n",
    "    $('.breadcrumb').hide();\n",
    "    $('.hidden-print').hide();\n",
    "  });\n",
    "</script>\n",
    "\n",
    "<footer id=\"attribution\" style=\"float:right; color:#999; background:#fff;\">\n",
    "Created with Jupyter Lab, by Nicholas Richers.\n",
    "</footer>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment #1 - Baseline Model vs. Baseline ML Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "The purpose of this experiment is to establish a baseline for a domain-driven model and to compare it to more sophisticated machine learning models using baseline features. Our baseline model will simply follow our intuited rule:\n",
    "\n",
    "> Select randomly a customer if they belong to tiers S or A, until we have an amount equivalent to 10% of our dataset (i.e 184), which sounds a reasonable amount of customers to be reached in a certain period of time (campaign).\n",
    "\n",
    "To estimate the performance of machine learning models, we will train the following models with some different hyperparameter configurations, selecting the best configuration and averaging the scores of the best models:\n",
    "\n",
    "* Logistic Regression\n",
    "* XGBoost\n",
    "* Light GBM\n",
    "* SGD Classifier\n",
    "* K-Nearest Neighboors\n",
    "\n",
    "Scores will be based on how well a classifier can prioritize 184 customers considering the entire database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from utils import code\n",
    "from plot_libraries import setup_graphics\n",
    "from datasets import get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries and set plot parameters\n",
    "import os, random, re, sys, time, warnings\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main Libraries\n",
    "import os, random, re, sys, time, warnings\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "#Data transform (pipeline)\n",
    "from sklearn.preprocessing import OneHotEncoder, FunctionTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler,RobustScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "# Model evaluation\n",
    "import scikitplot as skplt\n",
    "from sklearn.metrics import make_scorer, roc_auc_score, brier_score_loss, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict\n",
    "from evaluation import plot_learning_curve, evaluate_model, plot_confusion_matrix\n",
    "\n",
    "# Support\n",
    "import parameters as params\n",
    "from model import Model, build_tuned_model\n",
    "from datasets import get_data\n",
    "from experiments import experiment_1, get_scorer\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activities_Last_30_Days</th>\n",
       "      <th>Employees</th>\n",
       "      <th>ZoomInfo_Employee_Range</th>\n",
       "      <th>ZoomInfo_Revenue_Range</th>\n",
       "      <th>Organic_Visits</th>\n",
       "      <th>Pct_Organic_Visits</th>\n",
       "      <th>SEO_Visits</th>\n",
       "      <th>URLs_Indexed</th>\n",
       "      <th>ZoomInfo_Global_HQ_Country</th>\n",
       "      <th>Annual_Revenue_converted</th>\n",
       "      <th>Adjusted_Industry</th>\n",
       "      <th>Account_ICP_Score</th>\n",
       "      <th>Account_ICP_Tier</th>\n",
       "      <th>Page_Count</th>\n",
       "      <th>Page_Count_Range</th>\n",
       "      <th>Alexa_Rank</th>\n",
       "      <th>Parent_Account_Status</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Account_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0012400000L5cmZ</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>61688430.0</td>\n",
       "      <td>0.34</td>\n",
       "      <td>61688430.0</td>\n",
       "      <td>27700000.0</td>\n",
       "      <td>non_US</td>\n",
       "      <td>3.333900e+06</td>\n",
       "      <td>Retail</td>\n",
       "      <td>91.667</td>\n",
       "      <td>Tier A</td>\n",
       "      <td>27700000.0</td>\n",
       "      <td>&gt;1M</td>\n",
       "      <td>331.0</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00124000004sEH5</th>\n",
       "      <td>51.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>19397082.0</td>\n",
       "      <td>0.93</td>\n",
       "      <td>28615923.0</td>\n",
       "      <td>76200.0</td>\n",
       "      <td>non_US</td>\n",
       "      <td>1.333560e+10</td>\n",
       "      <td>Retail</td>\n",
       "      <td>100.000</td>\n",
       "      <td>Tier A</td>\n",
       "      <td>206300.0</td>\n",
       "      <td>Between 100K and 250K</td>\n",
       "      <td>8881.0</td>\n",
       "      <td>Prospect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00124000004sUGG</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>49283858.0</td>\n",
       "      <td>0.53</td>\n",
       "      <td>50132407.0</td>\n",
       "      <td>12600000.0</td>\n",
       "      <td>non_US</td>\n",
       "      <td>5.556500e+08</td>\n",
       "      <td>Media</td>\n",
       "      <td>100.000</td>\n",
       "      <td>Tier A</td>\n",
       "      <td>12709000.0</td>\n",
       "      <td>&gt;1M</td>\n",
       "      <td>1118.0</td>\n",
       "      <td>Lost Customer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0011p00002SeaiQ</th>\n",
       "      <td>0.0</td>\n",
       "      <td>383.0</td>\n",
       "      <td>250 - 500</td>\n",
       "      <td>$50 mil. - $100 mil.</td>\n",
       "      <td>177515.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>177515.0</td>\n",
       "      <td>1090000.0</td>\n",
       "      <td>US</td>\n",
       "      <td>7.360000e+07</td>\n",
       "      <td>Classified</td>\n",
       "      <td>70.833</td>\n",
       "      <td>Tier A</td>\n",
       "      <td>1090000.0</td>\n",
       "      <td>&gt;1M</td>\n",
       "      <td>126905.0</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0011p00001SghSL</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>1,000 - 5,000</td>\n",
       "      <td>$500 mil. - $1 bil.</td>\n",
       "      <td>8052961.0</td>\n",
       "      <td>0.59</td>\n",
       "      <td>10416602.0</td>\n",
       "      <td>2340000.0</td>\n",
       "      <td>US</td>\n",
       "      <td>2.500000e+08</td>\n",
       "      <td>Classified</td>\n",
       "      <td>100.000</td>\n",
       "      <td>Tier A</td>\n",
       "      <td>3640000.0</td>\n",
       "      <td>&gt;1M</td>\n",
       "      <td>4742.0</td>\n",
       "      <td>Prospect</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Activities_Last_30_Days  Employees ZoomInfo_Employee_Range  \\\n",
       "Account_ID                                                                    \n",
       "0012400000L5cmZ                      0.0       10.0                 unknown   \n",
       "00124000004sEH5                     51.0    10000.0                 unknown   \n",
       "00124000004sUGG                      0.0     5000.0                 unknown   \n",
       "0011p00002SeaiQ                      0.0      383.0               250 - 500   \n",
       "0011p00001SghSL                      0.0     5000.0           1,000 - 5,000   \n",
       "\n",
       "                ZoomInfo_Revenue_Range  Organic_Visits  Pct_Organic_Visits  \\\n",
       "Account_ID                                                                   \n",
       "0012400000L5cmZ                unknown      61688430.0                0.34   \n",
       "00124000004sEH5                unknown      19397082.0                0.93   \n",
       "00124000004sUGG                unknown      49283858.0                0.53   \n",
       "0011p00002SeaiQ   $50 mil. - $100 mil.        177515.0                 NaN   \n",
       "0011p00001SghSL    $500 mil. - $1 bil.       8052961.0                0.59   \n",
       "\n",
       "                 SEO_Visits  URLs_Indexed ZoomInfo_Global_HQ_Country  \\\n",
       "Account_ID                                                             \n",
       "0012400000L5cmZ  61688430.0    27700000.0                     non_US   \n",
       "00124000004sEH5  28615923.0       76200.0                     non_US   \n",
       "00124000004sUGG  50132407.0    12600000.0                     non_US   \n",
       "0011p00002SeaiQ    177515.0     1090000.0                         US   \n",
       "0011p00001SghSL  10416602.0     2340000.0                         US   \n",
       "\n",
       "                 Annual_Revenue_converted Adjusted_Industry  \\\n",
       "Account_ID                                                    \n",
       "0012400000L5cmZ              3.333900e+06            Retail   \n",
       "00124000004sEH5              1.333560e+10            Retail   \n",
       "00124000004sUGG              5.556500e+08             Media   \n",
       "0011p00002SeaiQ              7.360000e+07        Classified   \n",
       "0011p00001SghSL              2.500000e+08        Classified   \n",
       "\n",
       "                 Account_ICP_Score Account_ICP_Tier  Page_Count  \\\n",
       "Account_ID                                                        \n",
       "0012400000L5cmZ             91.667           Tier A  27700000.0   \n",
       "00124000004sEH5            100.000           Tier A    206300.0   \n",
       "00124000004sUGG            100.000           Tier A  12709000.0   \n",
       "0011p00002SeaiQ             70.833           Tier A   1090000.0   \n",
       "0011p00001SghSL            100.000           Tier A   3640000.0   \n",
       "\n",
       "                      Page_Count_Range  Alexa_Rank Parent_Account_Status  \n",
       "Account_ID                                                                \n",
       "0012400000L5cmZ                    >1M       331.0               unknown  \n",
       "00124000004sEH5  Between 100K and 250K      8881.0              Prospect  \n",
       "00124000004sUGG                    >1M      1118.0         Lost Customer  \n",
       "0011p00002SeaiQ                    >1M    126905.0               unknown  \n",
       "0011p00001SghSL                    >1M      4742.0              Prospect  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = get_data('../data/trainDF.csv')\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances: 1,849\n",
      "Number of conversions 315\n",
      "Conversion rate: 17.04%\n",
      "Expected number of conversions targeting 184 @ 17.04%: 31\n"
     ]
    }
   ],
   "source": [
    "n_instances = len(X)\n",
    "p_instances = y.sum() / len(y)\n",
    "p_targeted = 0.1 ##475/n_instances\n",
    "n_targeted = int(n_instances*p_targeted)\n",
    "\n",
    "print('Number of instances: {:,}'.format(n_instances))\n",
    "print('Number of conversions {:,}'.format(y.sum()))\n",
    "print('Conversion rate: {:.2f}%'.format(p_instances*100.))\n",
    "print('Expected number of conversions targeting {:,} @ {:.2f}%: {:,}'.format(n_targeted, p_instances*100., int(p_instances * n_targeted)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, stratify=y, random_state=1)\n",
    "n_targeted_test = int(len(X_test) * p_targeted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate our baseline model, we will include some financial features, which will allow us to compare with ML models later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup costs and benefits\n",
    "avg_revenue = params.AVG_REVENUE\n",
    "avg_cost = params.AVG_COST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the targeted and random groups\n",
    "baseline_targets = X_test[X_test.Account_ICP_Tier.isin(['Tier S', 'Tier A'])].sample(n=n_targeted_test, random_state=1)\n",
    "baseline_ys = y_test.loc[baseline_targets.index]\n",
    "baseline_outcomes = baseline_ys.apply(lambda x: avg_cost if x == 0 else avg_cost + avg_revenue)\n",
    "assert(len(baseline_targets) == n_targeted_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the random targets\n",
    "random_targets = X_test.sample(n=n_targeted_test)\n",
    "random_ys = y.loc[random_targets.index]\n",
    "random_outcomes = random_ys.apply(lambda x: avg_cost if x == 0 else avg_cost + avg_revenue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of customers targeted: 37/370\n",
      "\n",
      "Conversion rate under random policy: 24.3%\n",
      "Expected profit under random policy: $8,630\n",
      "\n",
      "Conversion rate under baseline policy: 27.0%\n",
      "Expected profit under baseline policy: $9,630\n",
      "Lift over random policy: 1.1 or $1,000\n"
     ]
    }
   ],
   "source": [
    "# Compute profit\n",
    "random_profit = sum(random_outcomes)\n",
    "baseline_profit = sum(baseline_outcomes)\n",
    "\n",
    "print('Number of customers targeted: {:,}/{:,}\\n'.format(len(baseline_targets), len(X_test)))\n",
    "\n",
    "print('Conversion rate under random policy: {:.1f}%'.format(random_ys.sum() / len(random_ys)*100.))\n",
    "print('Expected profit under random policy: ${:,}\\n'.format(random_profit))\n",
    "\n",
    "print('Conversion rate under baseline policy: {:.3}%'.format(baseline_ys.sum() / len(baseline_ys)*100.))\n",
    "print('Expected profit under baseline policy: ${:,}'.format(baseline_profit))\n",
    "print('Lift over random policy: {:.1f} or ${:,}'.format(baseline_profit / random_profit, baseline_profit - random_profit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n",
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline ML models\n",
    "We will evaluate some ML models and choose the best one under a score function then analyze its predictions and estimate financial impact."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From previous step, we noticed that some trasformations are necessary to improve our ML models.\n",
    "\n",
    "##### Fill nan values (however some models are robust to this issue).\n",
    "\n",
    "* #1 - fill_value=nan (*only valid to XGB & LGBM*)\n",
    "\n",
    "```python\n",
    "cat_ct = ColumnTransformer([('numerics', 'passthrough', experiment_1.NUM_FEAT)])\n",
    "```\n",
    "--------\n",
    "\n",
    "* #2 - fill_value=-1, let the model find out a pattern from its own (**best choice**)\n",
    "\n",
    "```python\n",
    "num_ct = ColumnTransformer([\n",
    "    ('fill_diff', SimpleImputer(missing_values=np.nan, strategy='constant',fill_value=-1),experiment_1.NUM_FEAT)                          \n",
    "])\n",
    "```\n",
    "--------\n",
    "\n",
    "* #3 - Multiple heuristics\n",
    "\n",
    "```python\n",
    "num_ct_ = ColumnTransformer([\n",
    "    ('numerics', 'passthrough', pass_feat),\n",
    "    ('fill_diff',SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=-1),fill_diff),\n",
    "    ('fill_max', SimpleImputer(missing_values=np.nan, strategy='most_frequent'),fill_max),\n",
    "    ('fill_min', SimpleImputer(missing_values=np.nan, strategy='constant', fill_value=0),fill_min)\n",
    "])\n",
    "```\n",
    "-------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the pipeline of first experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the transformers for categorical features\n",
    "cat_ct = ColumnTransformer([('categoricals', 'passthrough', experiment_1.CAT_FEAT)])\n",
    "\n",
    "# Create the pipeline to transform categorical features\n",
    "cat_pipeline = Pipeline([\n",
    "        ('cat_ct', cat_ct),\n",
    "        ('ohe', OneHotEncoder(handle_unknown='ignore'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the transformers for numeric features\n",
    "num_ct = ColumnTransformer([\n",
    "    ('fill_diff', SimpleImputer(missing_values=np.nan, strategy='constant',fill_value=-1),experiment_1.NUM_FEAT)                          \n",
    "])\n",
    "\n",
    "# Create the pipeline to transform numeric features\n",
    "num_pipeline = Pipeline([\n",
    "        ('num_union', num_ct),\n",
    "        ('scaler', RobustScaler()),\n",
    "        ('minimax', MinMaxScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concat both pipelines and transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instances: 1,849, Features: 63\n"
     ]
    }
   ],
   "source": [
    "pipeline1 = experiment_1.get_pipeline(cat_pipeline, num_pipeline)\n",
    "ps = pipeline1.fit_transform(X).shape\n",
    "print('Instances: {:,}, Features: {}'.format(ps[0], ps[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluation Metric\n",
    "As we need to estimate probabilities we will impement the brier_score_loss metric (0..1, smaller ir better)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = make_scorer(brier_score_loss, needs_proba=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ML Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Starting 5-fold cross validation for lr model, 1849 examples\n",
      "==> Elapsed seconds: 2.759\n",
      "Best lr model: LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='warn', n_jobs=None, penalty='l1',\n",
      "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "Best lr score: -0.019\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_param_grid = {\n",
    "  'lr__C': np.logspace(-3, 2, 6),\n",
    "  'lr__intercept_scaling': [1], \n",
    "  'lr__max_iter': [100],\n",
    "  'lr__penalty':  ['l1', 'l2'],\n",
    "  'lr__solver': ['liblinear'], #good for small datasets\n",
    "  'lr__tol': [0.0001]\n",
    "}\n",
    "\n",
    "\n",
    "#0.593\n",
    "result = evaluate_model(X, y, 'lr', LogisticRegression(), lr_param_grid, scorer, n_iter=50, cv_folds=5, pipeline=pipeline1)\n",
    "results.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Starting 5-fold cross validation for xgb model, 1849 examples\n",
      "==> Elapsed seconds: 29.538\n",
      "Best xgb model: XGBClassifier(base_score=0.5, booster=None, colsample_bylevel=0.4,\n",
      "              colsample_bynode=1, colsample_bytree=0.7, gamma=0.05, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints=None,\n",
      "              learning_rate=0.01, max_delta_step=0, max_depth=12,\n",
      "              min_child_weight=9, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=350, n_jobs=0, num_parallel_tree=1,\n",
      "              objective='binary:logistic', random_state=0,\n",
      "              reg_alpha=0.04641588833612779, reg_lambda=0.027825594022071243,\n",
      "              scale_pos_weight=1, subsample=0.8, tree_method=None,\n",
      "              validate_parameters=False, verbosity=None)\n",
      "Best xgb score: 0.055\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb_param_grid = {\n",
    "        'xgb__colsample_bylevel' : [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 1.0],\n",
    "        'xgb__colsample_bytree' :[0.6, 0.7, 0.8, 1.0],\n",
    "        'xgb__gamma' : list(np.linspace(0.05, 1, 6)),\n",
    "        'xgb__learning_rate' : [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3],\n",
    "        'xgb__max_depth' : list(range(3, 30, 3)),\n",
    "        'xgb__min_child_weight' : list(range(1, 11, 2)),\n",
    "        'xgb__n_estimators' : list(range(50, 400, 50)),\n",
    "        'xgb__reg_alpha' : list(np.logspace(-1, 1, num=10)/10),\n",
    "        'xgb__reg_lambda' : list(np.logspace(-1, 1, num=10)/10),\n",
    "        'xgb__subsample' : [0.6, 0.7, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "#.668\n",
    "result = evaluate_model(X, y, 'xgb', XGBClassifier(), xgb_param_grid, scorer, n_iter=20, cv_folds=5, pipeline=pipeline1)\n",
    "results.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Starting 5-fold cross validation for lgbm model, 1849 examples\n",
      "==> Elapsed seconds: 6.632\n",
      "Best lgbm model: LGBMClassifier(boosting_type='goss', class_weight=None,\n",
      "               colsample_bytree=0.7777777777777778, importance_type='split',\n",
      "               is_unbalance=False, learning_rate=0.04507388157262458,\n",
      "               max_depth=-1, min_child_samples=495, min_child_weight=0.001,\n",
      "               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=108,\n",
      "               objective=None, random_state=None, reg_alpha=0.14285714285714285,\n",
      "               reg_lambda=0.7142857142857142, silent=True,\n",
      "               subsample=0.9494949494949496, subsample_for_bin=280000,\n",
      "               subsample_freq=0)\n",
      "Best lgbm score: 0.104\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "lgbm_param_grid = {\n",
    "    'lgbm__boosting_type': ['gbdt', 'goss', 'dart'],\n",
    "    'lgbm__num_leaves': list(range(20, 150)),\n",
    "    'lgbm__learning_rate': list(np.logspace(np.log10(0.005), np.log10(0.5), base = 10, num = 1000)),\n",
    "    'lgbm__subsample_for_bin': list(range(20000, 300000, 20000)),\n",
    "    'lgbm__min_child_samples': list(range(20, 500, 5)),\n",
    "    'lgbm__reg_alpha': list(np.linspace(0, 1)),\n",
    "    'lgbm__reg_lambda': list(np.linspace(0, 1)),\n",
    "    'lgbm__colsample_bytree': list(np.linspace(0.6, 1, 10)),\n",
    "    'lgbm__subsample': list(np.linspace(0.5, 1, 100)),\n",
    "    'lgbm__is_unbalance': [True, False]\n",
    "}\n",
    "\n",
    "#0.739\n",
    "result = evaluate_model(X, y, 'lgbm', LGBMClassifier(), lgbm_param_grid, scorer, n_iter=20, cv_folds=5, pipeline=pipeline1)\n",
    "results.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Starting 5-fold cross validation for sgd model, 1849 examples\n",
      "==> Elapsed seconds: 2.776\n",
      "Best sgd model: SGDClassifier(alpha=0.1, average=False, class_weight=None, early_stopping=False,\n",
      "              epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "              learning_rate='optimal', loss='log', max_iter=1000,\n",
      "              n_iter_no_change=5, n_jobs=-1, penalty='l2', power_t=0.5,\n",
      "              random_state=None, shuffle=True, tol=0.001,\n",
      "              validation_fraction=0.1, verbose=0, warm_start=False)\n",
      "Best sgd score: -0.064\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd_param_grid = {\n",
    "  'sgd__alpha' : np.logspace(-4, 3, 8), \n",
    "  'sgd__loss' : ['log'], #['log','hinge'],\n",
    "  'sgd__max_iter' : [1000],  \n",
    "  'sgd__n_jobs' : [-1], \n",
    "  'sgd__penalty' : ['l2', 'l1', 'elasticnet'],\n",
    "  'sgd__tol' : [0.001],\n",
    "}\n",
    "\n",
    "\n",
    "#0.606\n",
    "result = evaluate_model(X, y, 'sgd', SGDClassifier(), sgd_param_grid, scorer, n_iter=20, cv_folds=5, pipeline=pipeline1)\n",
    "results.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Starting 5-fold cross validation for knn model, 1849 examples\n",
      "==> Elapsed seconds: 14.795\n",
      "Best knn model: KNeighborsClassifier(algorithm='auto', leaf_size=16, metric='euclidean',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=14, p=3,\n",
      "                     weights='uniform')\n",
      "Best knn score: -0.216\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_param_grid =  {\n",
    "  'knn__leaf_size' : list(range(2, 40, 2)), \n",
    "  'knn__metric' : ['euclidean', 'manhattan'],\n",
    "  'knn__n_neighbors' : list(range(2, 18, 2)), \n",
    "  'knn__p' : [2,3],\n",
    "  'knn__weights' : ['uniform', 'distance']\n",
    "}\n",
    "\n",
    "#0.526\n",
    "result = evaluate_model(X, y, 'knn', KNeighborsClassifier(), knn_param_grid, scorer, n_iter=20, cv_folds=5, pipeline=pipeline1)\n",
    "results.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(list(map(lambda x:\n",
    "                      {'model': x[1], 'mean': x[2], 'std': x[3] }, results)))[[\n",
    "                       'model', 'mean', 'std'\n",
    "                      ]].sort_values('mean', ascending=True)#.style.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_result = list(filter(lambda x: x[1] == 'lgbm', results))[0]\n",
    "model = model_result[0]\n",
    "print('Best model performance mean:', model_result[2])\n",
    "print('Best model performance std:', model_result[3])\n",
    "#model.save('../models_pkl/experiment-1-model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------\n",
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model.load('../models_pkl/experiment-1-model.pkl')\n",
    "model.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = get_scorer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our best model performs worst than a random model when we have only 10% of our data (i.e AUC=0.5), however the performance comes better as the dataset size increase, it also suffers with high variance on validation score (such as linear models). The last two statements indicates that we may need more data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_result = list(filter(lambda x: x[1] == 'xgb', results))[0]\n",
    "model = model_result[0]\n",
    "plot_learning_curve(model.model, \n",
    "                    model.name.upper()+' Learning Curves',\n",
    "                    model.pipeline.fit_transform(X), y,\n",
    "                    cv=5, scoring=scorer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#precisao da classe 1 baixa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = cross_val_predict(model.get_model_pipeline(), X, y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(y, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = model.model.predict_proba(model.pipeline.transform(X_test))\n",
    "preds = model.model.predict(model.pipeline.transform(X_test))\n",
    "plot_confusion_matrix(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = skplt.metrics.cumulative_gain_curve(y_test, probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe of probabilities and actual / predicted outcomes\n",
    "probs_df = pd.DataFrame(np.hstack([probs, y_test.values.reshape(-1,1), preds.reshape(-1,1)]), \n",
    "                        columns=['p_no', 'p_yes', 'actual', 'predicted'])\n",
    "\n",
    "\n",
    "# Sort customers by the probability that they will convert\n",
    "model_targets = probs_df.sort_values('p_yes', ascending=False)\n",
    "\n",
    "# Take the top 10%\n",
    "model_targets = model_targets.head(n_targeted_test)\n",
    "\n",
    "# Calculate financial outcomes\n",
    "model_outcomes = model_targets.actual.apply(lambda x: avg_cost if x == 0 else avg_cost + avg_revenue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(model_targets.actual, model_targets.predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDP SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_targets.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_targets.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparar HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Financial Impact of the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate profit\n",
    "model_profit = sum(model_outcomes)\n",
    "\n",
    "print('Number of customers targeted: {:,}/{:,}'.format(len(model_targets), len(X_test)))\n",
    "print('Conversion rate of model policy: {:.2f}%'.format(model_targets.actual.sum() / len(model_outcomes)*100.))\n",
    "print('Expected profit of model policy: ${:,}'.format(model_profit))\n",
    "print('Lift over random: {:.1f} or ${:,}'.format(model_profit / random_profit, model_profit - random_profit))\n",
    "print('Lift over baseline: {:.1f} or ${:,}'.format(model_profit / baseline_profit, model_profit - baseline_profit))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<script>\n",
    "  jQuery(document).ready(function($) {\n",
    "\n",
    "  $(window).load(function(){\n",
    "    $('#preloader').fadeOut('slow',function(){$(this).remove();});\n",
    "  });\n",
    "\n",
    "  });\n",
    "</script>\n",
    "\n",
    "<style type=\"text/css\">\n",
    "  div#preloader { position: fixed;\n",
    "      left: 0;\n",
    "      top: 0;\n",
    "      z-index: 999;\n",
    "      width: 100%;\n",
    "      height: 100%;\n",
    "      overflow: visible;\n",
    "      background: #fff url('http://preloaders.net/preloaders/720/Moving%20line.gif') no-repeat center center;\n",
    "  }\n",
    "\n",
    "</style>\n",
    "\n",
    "<div id=\"preloader\"></div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
